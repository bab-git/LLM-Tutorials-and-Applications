{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and Basics of Chatbots and Conversational Agents\n",
    "\n",
    "In this notebook, we work on the following topics:\n",
    "- A direct API call from OpenAI to perform chat completions\n",
    "- Chat completions with Langchain APIs\n",
    "- Using prompt template to create custom prompt\n",
    "- Using output parser to extract key information from the completion\n",
    "\n",
    "We are going to covers samples from the following use case:\n",
    "- Technical support as a chatbot technician.\n",
    "- Entity extraction from cusomer travel query.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "import pprint\n",
    "\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "# openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "import sys\n",
    "module_dir = os.path.abspath('src')  # Gets the absolute path to the src directory\n",
    "sys.path.append(module_dir)\n",
    "from helper_functions import llm_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function for printing nicely\n",
    "def nprint(text, indent=2):\n",
    "    pp = pprint.PrettyPrinter(indent=indent)\n",
    "    pp.pprint(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelID = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical support as a chatbot technician.\n",
    "Here the LLM chatbot gives technical support to the customer to fix it's problem.  \n",
    "We use system context as well as answering styles to customize the chatbot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API call from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('If your screen freezes, you can try the following steps to resolve the '\n",
      " 'issue:\\n'\n",
      " '\\n'\n",
      " '1. Wait a few moments: Sometimes the screen may freeze temporarily, so give '\n",
      " 'it a few moments to see if it resolves on its own.\\n'\n",
      " '\\n'\n",
      " \"2. Restart your device: If waiting doesn't work, try restarting your device. \"\n",
      " 'This can help refresh the system and resolve any temporary issues causing '\n",
      " 'the freeze.\\n'\n",
      " '\\n'\n",
      " \"3. Check for software updates: Make sure your device's operating system and \"\n",
      " 'apps are up to date. Sometimes freezes can occur due to outdated software.\\n'\n",
      " '\\n'\n",
      " '4. Close any unresponsive apps: If a specific app is causing the freeze, try '\n",
      " 'closing it by using the task manager or force quitting the app.\\n'\n",
      " '\\n'\n",
      " '5. Clear cache: Clearing the cache on your device can sometimes help resolve '\n",
      " 'freezing issues. You can do this through the settings menu on your device.\\n'\n",
      " '\\n'\n",
      " '6. Perform a factory reset: If the freeze persists and none of the above '\n",
      " 'steps work, you may need to perform a factory reset on your device. Make '\n",
      " 'sure to back up your important data before doing this.\\n'\n",
      " '\\n'\n",
      " 'If the issue continues after trying these steps, you may need to contact the '\n",
      " 'manufacturer or a technical support professional for further assistance.')\n"
     ]
    }
   ],
   "source": [
    "question = \"What do I do if my screen freezes?\"\n",
    "completion = llm_completion(question, model=modelID)\n",
    "nprint(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on the completion Style and System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1. Try pressing Ctrl + Alt + Delete to open the Task Manager.\\n'\n",
      " '2. In the Task Manager, select the unresponsive program and click on \"End '\n",
      " 'Task.\"\\n'\n",
      " \"3. If that doesn't work, try restarting your computer by holding down the \"\n",
      " 'power button until it shuts off.\\n'\n",
      " '4. Once the computer is off, wait a few seconds and then turn it back on.\\n'\n",
      " '5. If the issue persists, consider checking for software updates or running '\n",
      " 'a virus scan to rule out any potential causes.')\n"
     ]
    }
   ],
   "source": [
    "sys_content = \"You are an expert technician who gives exact, clear, and short steps to solving a problem.\"\n",
    "completion = llm_completion(question, model=modelID, sys_content=sys_content)\n",
    "nprint(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets change the style of the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do I do if my screen freezes? \n",
      "The answer must be understabdable for a 5 year old child.\n",
      "\n",
      "('1. Press and hold the power button on your device until it turns off.\\n'\n",
      " '2. Wait a few seconds, then turn it back on.\\n'\n",
      " '3. If the screen is still frozen, try restarting your device again.\\n'\n",
      " '4. If the problem persists, ask an adult for help or take your device to a '\n",
      " 'technician.')\n"
     ]
    }
   ],
   "source": [
    "style = \"The answer must be understabdable for a 5 year old child.\"\n",
    "prompt = f\"\"\"{question} \n",
    "{style}\n",
    "\"\"\"\n",
    "print(prompt)\n",
    "\n",
    "completion = llm_completion(prompt, model=modelID, sys_content=sys_content)\n",
    "nprint(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it even more simpler for the child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('If your screen freezes, just give it a little break like when you eat too '\n",
      " 'much ice cream too fast and get brain freeze. Turn it off and then back on '\n",
      " 'again, like a magic trick! It might start working again like nothing ever '\n",
      " \"happened. If that doesn't work, ask a grown-up for help because they know \"\n",
      " 'all the tricks!')\n"
     ]
    }
   ],
   "source": [
    "sys_content = \"You are a cool 5 years old child with funny sense of humor.\"\n",
    "\n",
    "completion = llm_completion(prompt, model=modelID, sys_content=sys_content)\n",
    "nprint(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it even more creative by increasing the tempreature of the LLM model to 2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Well kiddo, when your screen freezes like a frozen snow cone, you can try '\n",
      " 'pressing the power button to make it take a nap and then wake it up by '\n",
      " \"turning it back on. If that doesn't work, you can always ask a grown-up to \"\n",
      " 'help figure things out!')\n"
     ]
    }
   ],
   "source": [
    "completion = llm_completion(prompt, model=modelID, sys_content=sys_content, temperature=2.0)\n",
    "nprint(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Langchain APIs to perform chat completions\n",
    "Now we perform the above chat completions using Langchain modules which are more simpler and easier to use.  \n",
    "We use prompt template to create the prompt with different style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Portfolio\\LLMs Applications\\.llmenv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question', 'style', 'sys_content'] template='{sys_content}\\nAnswer this following question:  \\n{question} \\nStyle: {style}\\n'\n",
      "['question', 'style', 'sys_content']\n"
     ]
    }
   ],
   "source": [
    "QAchat = ChatOpenAI(temperature=0, model=modelID)\n",
    "template = \"\"\"{sys_content}\n",
    "Answer this following question:  \n",
    "{question} \n",
    "Style: {style}\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "print(prompt_template.messages[0].prompt)\n",
    "print(prompt_template.messages[0].prompt.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='You are a cool 5 years old child with funny sense of humor.\\nAnswer this following question:  \\nWhy do cats always land on their feet? \\nStyle: The answer must be understabdable for a 5 year old child.\\n')]\n",
      "The formated prompt is:\n",
      "\n",
      "('You are a cool 5 years old child with funny sense of humor.\\n'\n",
      " 'Answer this following question:  \\n'\n",
      " 'Why do cats always land on their feet? \\n'\n",
      " 'Style: The answer must be understabdable for a 5 year old child.\\n')\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format_messages(\n",
    "                    sys_content = sys_content,\n",
    "                    style=style,\n",
    "                    question=question)\n",
    "print(prompt)\n",
    "print(\"The formated prompt is:\\n\")\n",
    "nprint(prompt[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Because they have special cat magnets in their paws that help them always '\n",
      " 'land on their feet!')\n"
     ]
    }
   ],
   "source": [
    "completion = QAchat(prompt)\n",
    "nprint(completion.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using output parser\n",
    "Here we use output parser to extract key information from the completion.  \n",
    "We need this information to be extracted as a JSON object, so we can use it as a dictionary.\n",
    "So, We define a custom format instructions to let LLM know what information must be extracted from the completion.\n",
    "\n",
    "**Use case**: Travel and Hospitality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample query from the user from which we extract the key information about the trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_query = \"\"\"\\\n",
    "We're planning a family vacation to Hawaii in December. \\\n",
    "We need recommendations for family-friendly hotels and activities suitable for kids. \\\n",
    "Also, any travel advisories we should be aware of?\\\n",
    "Our budget for the entire trip is around $5000.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use ResponseSchema to define how the key information must be extracted from the completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"destination\": string  // What is the destination of the trip?\n",
      "\t\"travel_date\": string  // When is the trip planned for?\n",
      "\t\"requests\": string  // Extract any specific requests made by the traveler,\n",
      "                                    and output them as a comma separated Python list.\n",
      "\t\"budget\": string  // What is the budget for the entire trip? \n",
      "                                If this information is not found, output -1.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "destination_schema = ResponseSchema(name=\"destination\",\n",
    "                             description=\"What is the destination of the trip?\")\n",
    "travel_date_schema = ResponseSchema(name=\"travel_date\",\n",
    "                                      description=\"When is the trip planned for?\")\n",
    "requests_schema = ResponseSchema(name=\"requests\",\n",
    "                                    description=\"\"\"Extract any specific requests made by the traveler,\n",
    "                                    and output them as a comma separated Python list.\"\"\")\n",
    "budget_schema = ResponseSchema(name=\"budget\",\n",
    "                             description=\"\"\"What is the budget for the entire trip? \n",
    "                                If this information is not found, output -1.\"\"\")\n",
    "\n",
    "completion_schemas = [destination_schema, \n",
    "                    travel_date_schema,\n",
    "                    requests_schema,\n",
    "                    budget_schema]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(completion_schemas)        \n",
    "# output_parser\n",
    "format_instructions = output_parser.get_format_instructions()            \n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['format_instructions', 'query'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'query'], template='For the following query, extract the following information:\\n\\ndestination: What is the destination of the trip?\\ntravel_date: When is the trip planned for?\\nrequests: Extract any specific requests made by the traveler,and output them as a comma separated Python list.\\n\\nbudget: What is the budget for the entire trip? If this information is not found, output -1.\\n\\nFormat the output as JSON with the following keys:\\ndestination\\ntravel_date\\nrequests\\nbudget\\n\\nquery: {query}\\n\\n{format_instructions}\\n'))]\n"
     ]
    }
   ],
   "source": [
    "vacation_template = \"\"\"\\\n",
    "For the following query, extract the following information:\n",
    "\n",
    "destination: What is the destination of the trip?\\\n",
    "\n",
    "travel_date: When is the trip planned for?\\\n",
    "\n",
    "requests: Extract any specific requests made by the traveler,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "budget: What is the budget for the entire trip? \\\n",
    "If this information is not found, output -1.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "destination\n",
    "travel_date\n",
    "requests\n",
    "budget\n",
    "\n",
    "query: {query}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(vacation_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='For the following query, extract the following information:\\n\\ndestination: What is the destination of the trip?\\ntravel_date: When is the trip planned for?\\nrequests: Extract any specific requests made by the traveler,and output them as a comma separated Python list.\\n\\nbudget: What is the budget for the entire trip? If this information is not found, output -1.\\n\\nFormat the output as JSON with the following keys:\\ndestination\\ntravel_date\\nrequests\\nbudget\\n\\nquery: We\\'re planning a family vacation to Hawaii in December. We need recommendations for family-friendly hotels and activities suitable for kids. Also, any travel advisories we should be aware of?Our budget for the entire trip is around $5000.\\n\\n\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"destination\": string  // What is the destination of the trip?\\n\\t\"travel_date\": string  // When is the trip planned for?\\n\\t\"requests\": string  // Extract any specific requests made by the traveler,\\n                                    and output them as a comma separated Python list.\\n\\t\"budget\": string  // What is the budget for the entire trip? \\n                                If this information is not found, output -1.\\n}\\n```\\n')]\n",
      "The formated prompt is:\n",
      "\n",
      "('For the following query, extract the following information:\\n'\n",
      " '\\n'\n",
      " 'destination: What is the destination of the trip?\\n'\n",
      " 'travel_date: When is the trip planned for?\\n'\n",
      " 'requests: Extract any specific requests made by the traveler,and output them '\n",
      " 'as a comma separated Python list.\\n'\n",
      " '\\n'\n",
      " 'budget: What is the budget for the entire trip? If this information is not '\n",
      " 'found, output -1.\\n'\n",
      " '\\n'\n",
      " 'Format the output as JSON with the following keys:\\n'\n",
      " 'destination\\n'\n",
      " 'travel_date\\n'\n",
      " 'requests\\n'\n",
      " 'budget\\n'\n",
      " '\\n'\n",
      " \"query: We're planning a family vacation to Hawaii in December. We need \"\n",
      " 'recommendations for family-friendly hotels and activities suitable for kids. '\n",
      " 'Also, any travel advisories we should be aware of?Our budget for the entire '\n",
      " 'trip is around $5000.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'The output should be a markdown code snippet formatted in the following '\n",
      " 'schema, including the leading and trailing \"```json\" and \"```\":\\n'\n",
      " '\\n'\n",
      " '```json\\n'\n",
      " '{\\n'\n",
      " '\\t\"destination\": string  // What is the destination of the trip?\\n'\n",
      " '\\t\"travel_date\": string  // When is the trip planned for?\\n'\n",
      " '\\t\"requests\": string  // Extract any specific requests made by the '\n",
      " 'traveler,\\n'\n",
      " '                                    and output them as a comma separated '\n",
      " 'Python list.\\n'\n",
      " '\\t\"budget\": string  // What is the budget for the entire trip? \\n'\n",
      " '                                If this information is not found, output '\n",
      " '-1.\\n'\n",
      " '}\\n'\n",
      " '```\\n')\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format_messages(\n",
    "    query = customer_query,\n",
    "    format_instructions = format_instructions)\n",
    "print(prompt)\n",
    "print(\"The formated prompt is:\\n\")\n",
    "nprint(prompt[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"destination\": \"Hawaii\",\n",
      "\t\"travel_date\": \"December\",\n",
      "\t\"requests\": \"family-friendly hotels, activities suitable for kids, travel advisories\",\n",
      "\t\"budget\": \"$5000\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "completion = QAchat(prompt)\n",
    "print(completion.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
